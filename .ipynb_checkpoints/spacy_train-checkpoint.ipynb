{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A tour of awesome features ofÂ spaCy\n",
    "\n",
    "## Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "#!python -m spacy download en_core_web_lg\n",
    "#!python -m spacy download en_vectors_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "doc = nlp(\"Jon Snow isn't the best dragon rider. But we will let it pass because he only learned last week.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 6th token is dragon\n",
      "The 7th token is rider\n"
     ]
    }
   ],
   "source": [
    "for token in doc[6:8]:\n",
    "    print('The {}th token is {}'.format(token.i, token.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dragon rider\n"
     ]
    }
   ],
   "source": [
    "print(doc[6:8].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jon Snow isn't the best dragon rider.\n"
     ]
    }
   ],
   "source": [
    "print(doc[6:8].sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jon', 'Snow', 'good', 'dragon', 'rider', '.']\n",
      "['let', 'pass', 'learn', 'week', '.']\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print([token.lemma_ for token in sent if not token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[6].has_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[6:8].has_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29920253"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[6:8].similarity(doc[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5618917"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sim = nlp('apple orange chair rumpelstiltskin')\n",
    "doc_sim[0].similarity(doc_sim[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17142111"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sim[0].similarity(doc_sim[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.114447676"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sim[0].similarity(doc_sim[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linguistic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best good ADJ JJS amod\n"
     ]
    }
   ],
   "source": [
    "token = doc[5]\n",
    "print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adjective'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"ADJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adjective, superlative'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"JJS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adjectival modifier'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"amod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"9139b86dc7384280aaf68bcdb9c5dd43-0\" class=\"displacy\" width=\"1250\" height=\"437.0\" direction=\"ltr\" style=\"max-width: none; height: 437.0px; color: black; background: orange; font-family: Source Sans Pro; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Jon</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">Snow</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">n't</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">best</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">dragon</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">rider.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9139b86dc7384280aaf68bcdb9c5dd43-0-0\" stroke-width=\"2px\" d=\"M62,302.0 62,277.0 191.0,277.0 191.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9139b86dc7384280aaf68bcdb9c5dd43-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,304.0 L58,296.0 66,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9139b86dc7384280aaf68bcdb9c5dd43-0-1\" stroke-width=\"2px\" d=\"M212,302.0 212,277.0 341.0,277.0 341.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9139b86dc7384280aaf68bcdb9c5dd43-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M212,304.0 L208,296.0 216,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9139b86dc7384280aaf68bcdb9c5dd43-0-2\" stroke-width=\"2px\" d=\"M362,302.0 362,277.0 491.0,277.0 491.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9139b86dc7384280aaf68bcdb9c5dd43-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M491.0,304.0 L495.0,296.0 487.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9139b86dc7384280aaf68bcdb9c5dd43-0-3\" stroke-width=\"2px\" d=\"M662,302.0 662,227.0 1097.0,227.0 1097.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9139b86dc7384280aaf68bcdb9c5dd43-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M662,304.0 L658,296.0 666,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9139b86dc7384280aaf68bcdb9c5dd43-0-4\" stroke-width=\"2px\" d=\"M812,302.0 812,252.0 1094.0,252.0 1094.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9139b86dc7384280aaf68bcdb9c5dd43-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M812,304.0 L808,296.0 816,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9139b86dc7384280aaf68bcdb9c5dd43-0-5\" stroke-width=\"2px\" d=\"M962,302.0 962,277.0 1091.0,277.0 1091.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9139b86dc7384280aaf68bcdb9c5dd43-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M962,304.0 L958,296.0 966,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-9139b86dc7384280aaf68bcdb9c5dd43-0-6\" stroke-width=\"2px\" d=\"M362,302.0 362,202.0 1100.0,202.0 1100.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-9139b86dc7384280aaf68bcdb9c5dd43-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,304.0 L1104.0,296.0 1096.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "options = {\"compact\": True, \"bg\": \"orange\",\n",
    "           \"color\": \"black\", \"font\": \"Source Sans Pro\"}\n",
    "displacy.render(next(doc.sents) , style=\"dep\", options=options) # use render instead of serve in jupyter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jon Snow\n",
      "last week\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Jon Snow\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " isn't the best dragon rider. But we will let it pass because he only learned \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    last week\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text)\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Jon Snow isn't the best dragon rider. But we will let it pass because he only learned \n",
       "<mark class=\"entity\" style=\"background: red; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    last week\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = {\"DATE\": \"red\"}\n",
    "options = {\"ents\": [\"DATE\"], \"colors\": colors}\n",
    "displacy.render(doc, style=\"ent\", options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpaCy universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es\n",
      "en\n"
     ]
    }
   ],
   "source": [
    "from spacy_langdetect import LanguageDetector\n",
    "nlp.add_pipe(LanguageDetector(), name=\"lang_detect\", last=True)\n",
    "doc_es = nlp('HabitaciÃ³n blanquÃ­sima del interior de la casa.')\n",
    "\n",
    "print(doc_es._.language['language'])\n",
    "print(doc_es.lang_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Jon Snow isn't the best dragon rider. But we will let the best dragon rider pass because Jon Snow only learned last week.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neuralcoref\n",
    "neuralcoref.add_to_pipe(nlp)\n",
    "doc = nlp(\"Jon Snow isn't the best dragon rider. But we will let it pass because he only learned last week.\")\n",
    "doc._.coref_resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Jon Snow: [Jon Snow, he], the best dragon rider: [the best dragon rider, it]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.coref_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{we: 0.2482292652130127,\n",
       " Jon Snow: -3.0058393478393555,\n",
       " the best dragon rider: -2.1889660358428955}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores for 'we'\n",
    "doc._.coref_scores[doc[10:11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{it: -0.1293228268623352,\n",
       " Jon Snow: -2.065023422241211,\n",
       " the best dragon rider: 2.3545587062835693,\n",
       " we: -3.415001392364502}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores for 'it':\n",
    "doc._.coref_scores[doc[13:14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{he: 0.27577924728393555,\n",
       " Jon Snow: 4.285954475402832,\n",
       " the best dragon rider: -1.2236950397491455,\n",
       " we: -4.129101753234863,\n",
       " it: -2.2169408798217773}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores for 'he'\n",
    "doc._.coref_scores[doc[16:17]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Jon Snow isn't the best dragon rider. But we will let it pass because Jon Snow only learned last week.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.remove_pipe(\"neuralcoref\")\n",
    "coref = neuralcoref.NeuralCoref(nlp.vocab, greedyness=0.45)\n",
    "nlp.add_pipe(coref, name='neuralcoref')\n",
    "doc = nlp(\"Jon Snow isn't the best dragon rider. But we will let it pass because he only learned last week.\")\n",
    "doc._.coref_resolved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>mlai</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Road Ahead: Artificial Intelligence will a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can Robots Teach Us How to Be Human?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vehicle DC Voltage Converter Step down 24V to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which Is The Best Tablet For Kids?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Top 10 Strongest Dog Breeds in the World</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  mlai\n",
       "0  The Road Ahead: Artificial Intelligence will a...     1\n",
       "1               Can Robots Teach Us How to Be Human?     1\n",
       "2  Vehicle DC Voltage Converter Step down 24V to ...     0\n",
       "3                 Which Is The Best Tablet For Kids?     0\n",
       "4           Top 10 Strongest Dog Breeds in the World     0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines \n",
    "with jsonlines.open('texts.jsonl', mode='w') as writer:\n",
    "    for text in train_df.title:\n",
    "        writer.write({'text':text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125517\n"
     ]
    }
   ],
   "source": [
    "# word count\n",
    "count = 0\n",
    "for title in train_df.title:\n",
    "    count += len(title.split())\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: spacy pretrain [-h] [-cw 96] [-cd 4] [-er 2000] [-L cosine] [-uv]\n",
      "                      [-d 0.2] [-i 1000] [-bs 3000] [-xw 500] [-nw 5] [-s 0]\n",
      "                      texts_loc vectors_model output_dir\n",
      "\n",
      "    Pre-train the 'token-to-vector' (tok2vec) layer of pipeline components,\n",
      "    using an approximate language-modelling objective. Specifically, we load\n",
      "    pre-trained vectors, and train a component like a CNN, BiLSTM, etc to predict\n",
      "    vectors which match the pre-trained ones. The weights are saved to a directory\n",
      "    after each epoch. You can then pass a path to one of these pre-trained weights\n",
      "    files to the 'spacy train' command.\n",
      "\n",
      "    This technique may be especially helpful if you have little labelled data.\n",
      "    However, it's still quite experimental, so your mileage may vary.\n",
      "\n",
      "    To load the weights back in during 'spacy train', you need to ensure\n",
      "    all settings are the same between pretraining and training. The API and\n",
      "    errors around this need some improvement.\n",
      "    \n",
      "\n",
      "positional arguments:\n",
      "  texts_loc             Path to jsonl file with texts to learn from\n",
      "  vectors_model         Name or path to vectors model to learn from\n",
      "  output_dir            Directory to write models each epoch\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  -cw 96, --width 96    Width of CNN layers\n",
      "  -cd 4, --depth 4      Depth of CNN layers\n",
      "  -er 2000, --embed-rows 2000\n",
      "                        Embedding rows\n",
      "  -L cosine, --loss-func cosine\n",
      "                        Loss to use for the objective. L2 or cosine\n",
      "  -uv, --use-vectors    Whether to use the static vectors as input features\n",
      "  -d 0.2, --dropout 0.2\n",
      "                        Dropout\n",
      "  -i 1000, --nr-iter 1000\n",
      "                        Number of iterations to pretrain\n",
      "  -bs 3000, --batch-size 3000\n",
      "                        Number of words per training batch\n",
      "  -xw 500, --max-length 500\n",
      "                        Max words per example.\n",
      "  -nw 5, --min-length 5\n",
      "                        Min words per example.\n",
      "  -s 0, --seed 0        Seed for random number generators\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy pretrain -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy pretrain texts.jsonl en_vectors_web_lg ./pretrained-model\n",
    "#!python -m spacy pretrain texts.jsonl en_vectors_web_lg ./pretrained-model-vecs --use-vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess trian data\n",
    "train_texts = train_df['title']\n",
    "train_cats = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)} \n",
    "                 for y in train_df['mlai']]\n",
    "\n",
    "# load and preprocess dev data\n",
    "dev_df = pd.read_csv('dev.csv')\n",
    "dev_texts = dev_df['title']\n",
    "dev_cats = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)} \n",
    "                 for y in dev_df['mlai']]\n",
    "\n",
    "train_data = list(zip(train_texts, [{\"cats\": cats} \n",
    "                                     for cats in train_cats]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The Android game for the Matching Clothes App',\n",
       " {'cats': {'POSITIVE': False, 'NEGATIVE': True}})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15896\n",
      "7937\n"
     ]
    }
   ],
   "source": [
    "print(len(train_texts))\n",
    "print(len(dev_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is modified from spaCy's user guide for TextCategorizer training \n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "def main(model=None, n_iter=5, init_tok2vec=None):\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "\n",
    "    # add the text classifier to the pipeline if it doesn't exist\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if \"textcat\" not in nlp.pipe_names:\n",
    "        textcat = nlp.create_pipe(\n",
    "            \"textcat\",\n",
    "            config={\n",
    "                \"exclusive_classes\": True,\n",
    "                \"architecture\": \"simple_cnn\",\n",
    "            }\n",
    "        )\n",
    "        nlp.add_pipe(textcat, last=True)\n",
    "    # otherwise, get it, so we can add labels to it\n",
    "    else:\n",
    "        textcat = nlp.get_pipe(\"textcat\")\n",
    "\n",
    "    # add label to text classifier\n",
    "    textcat.add_label(\"POSITIVE\")\n",
    "    textcat.add_label(\"NEGATIVE\")\n",
    "\n",
    "    # load the datasets\n",
    "    print(\"Loading data...\")\n",
    "    train_df = pd.read_csv('train.csv')\n",
    "    train_texts = train_df['title']\n",
    "    train_cats = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)} \n",
    "                     for y in train_df['mlai']]\n",
    "\n",
    "    dev_df = pd.read_csv('dev.csv')\n",
    "    dev_texts = dev_df['title']\n",
    "    dev_cats = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)} \n",
    "                     for y in dev_df['mlai']]\n",
    "\n",
    "    print(\n",
    "        \"Using {} examples ({} training, {} evaluation)\".format(\n",
    "            len(train_texts) + len(dev_texts), len(train_texts), len(dev_texts)\n",
    "        )\n",
    "    )\n",
    "    train_data = list(zip(train_texts, [{\"cats\": cats} for cats in train_cats]))\n",
    "        \n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"textcat\"]\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "        optimizer = nlp.begin_training()\n",
    "        if init_tok2vec is not None:\n",
    "            init_tok2vec = Path(init_tok2vec)\n",
    "            with init_tok2vec.open(\"rb\") as file_:\n",
    "                textcat.model.tok2vec.from_bytes(file_.read())\n",
    "        print(\"Training the model...\")\n",
    "        print(\"{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\".format(\"LOSS\", \"A\", \"P\", \"R\", \"F\"))\n",
    "        batch_sizes = compounding(4.0, 32.0, 1.001)\n",
    "        for i in range(n_iter):\n",
    "            losses = {}\n",
    "            # batch up the examples using spaCy's minibatch\n",
    "            random.shuffle(train_data)\n",
    "            batches = minibatch(train_data, size=batch_sizes)\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                nlp.update(texts, annotations, sgd=optimizer, drop=0.2, losses=losses)\n",
    "            with textcat.model.use_params(optimizer.averages):\n",
    "                # evaluate on the dev data split off in load_data()\n",
    "                scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "            print(\n",
    "                \"{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}\\t{4:.3f}\".format(  # print a simple table\n",
    "                    losses[\"textcat\"],\n",
    "                    scores[\"textcat_a\"],\n",
    "                    scores[\"textcat_p\"],\n",
    "                    scores[\"textcat_r\"],\n",
    "                    scores[\"textcat_f\"],\n",
    "                )\n",
    "            )\n",
    "\n",
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 0.0  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 0.0  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if label == \"NEGATIVE\":\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.0\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.0\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    accuracy = (tp + tn) / (tp + tn + fn + fp)\n",
    "    if (precision + recall) == 0:\n",
    "        f_score = 0.0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {\"textcat_a\": accuracy, \"textcat_p\": precision, \"textcat_r\": recall, \"textcat_f\": f_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'en_core_web_lg'\n",
      "Loading data...\n",
      "Using 23833 examples (15896 training, 7937 evaluation)\n",
      "Training the model...\n",
      "LOSS \t  A  \t  P  \t  R  \t  F  \n",
      "6.116\t0.884\t0.876\t0.908\t0.892\n",
      "0.059\t0.886\t0.878\t0.909\t0.893\n",
      "0.023\t0.884\t0.876\t0.908\t0.892\n",
      "0.018\t0.881\t0.868\t0.914\t0.890\n",
      "0.014\t0.880\t0.871\t0.906\t0.888\n"
     ]
    }
   ],
   "source": [
    "main(model='en_core_web_lg', init_tok2vec='pretrained-model-lg-tags/model999.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'en_core_web_lg'\n",
      "Loading data...\n",
      "Using 23833 examples (15896 training, 7937 evaluation)\n",
      "Training the model...\n",
      "LOSS \t  A  \t  P  \t  R  \t  F  \n",
      "7.667\t0.878\t0.871\t0.902\t0.886\n",
      "0.073\t0.878\t0.866\t0.908\t0.886\n",
      "0.028\t0.872\t0.862\t0.900\t0.881\n",
      "0.024\t0.872\t0.862\t0.902\t0.881\n",
      "0.018\t0.868\t0.856\t0.900\t0.877\n"
     ]
    }
   ],
   "source": [
    "main(model='en_core_web_lg', init_tok2vec=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "Loading data...\n",
      "Using 23833 examples (15896 training, 7937 evaluation)\n",
      "Training the model...\n",
      "LOSS \t  A  \t  P  \t  R  \t  F  \n",
      "7.026\t0.871\t0.851\t0.913\t0.881\n",
      "0.065\t0.868\t0.858\t0.897\t0.877\n",
      "0.024\t0.867\t0.859\t0.895\t0.877\n",
      "0.017\t0.859\t0.853\t0.885\t0.869\n",
      "0.016\t0.862\t0.855\t0.888\t0.871\n"
     ]
    }
   ],
   "source": [
    "main(model=None, init_tok2vec='pretrained-model-tags/model999.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "Loading data...\n",
      "Using 23833 examples (15896 training, 7937 evaluation)\n",
      "Training the model...\n",
      "LOSS \t  A  \t  P  \t  R  \t  F  \n",
      "9.946\t0.850\t0.837\t0.886\t0.861\n",
      "0.081\t0.855\t0.844\t0.888\t0.865\n",
      "0.034\t0.852\t0.842\t0.885\t0.863\n",
      "0.025\t0.851\t0.842\t0.883\t0.862\n",
      "0.021\t0.846\t0.838\t0.877\t0.857\n"
     ]
    }
   ],
   "source": [
    "main(model=None, init_tok2vec=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'en_core_web_lg'\n",
      "Loading data...\n",
      "Using 23833 examples (15896 training, 7937 evaluation)\n",
      "Training the model...\n",
      "LOSS \t  A  \t  P  \t  R  \t  F  \n",
      "6.693\t0.883\t0.879\t0.902\t0.891\n",
      "0.066\t0.877\t0.869\t0.902\t0.885\n",
      "0.025\t0.874\t0.867\t0.899\t0.883\n",
      "0.021\t0.875\t0.868\t0.899\t0.883\n",
      "0.017\t0.869\t0.863\t0.893\t0.878\n"
     ]
    }
   ],
   "source": [
    "main(model='en_core_web_lg', init_tok2vec='pretrained-model-lg-tags/model50.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "Loading data...\n",
      "Using 23833 examples (15896 training, 7937 evaluation)\n",
      "Training the model...\n",
      "LOSS \t  A  \t  P  \t  R  \t  F  \n",
      "8.077\t0.856\t0.842\t0.894\t0.868\n",
      "0.078\t0.860\t0.852\t0.888\t0.870\n",
      "0.030\t0.857\t0.852\t0.881\t0.867\n",
      "0.024\t0.855\t0.849\t0.880\t0.864\n",
      "0.018\t0.853\t0.849\t0.876\t0.862\n"
     ]
    }
   ],
   "source": [
    "main(model=None, init_tok2vec='pretrained-model-tags/model50.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
